{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41646060-62e7-4a24-ac89-3b712b652d4b",
   "metadata": {},
   "source": [
    "# Project-Step 1:\n",
    "\n",
    "At this first stage of your project, complete the following tasks by providing your notebook (in .pybn format or\n",
    "converted to HTML):\n",
    "1. Descriptive analysis of your data.\n",
    "2. Implementation of the necessary pre-processing.\n",
    "3. Formalisation of the problem.\n",
    "4. Selection of a baseline model and implementation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e06483-ef86-4177-9a2c-ac217c3fc2f7",
   "metadata": {},
   "source": [
    "# Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2782cba7-3325-4033-9c68-1b02d5fc48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae199-8e09-4825-8ee0-30a72863c57e",
   "metadata": {},
   "source": [
    "# Gestion des erreurs en cas de soucis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6187ea44-eaf4-41a9-8375-53ea61e0fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b94d80-b52e-452a-b66e-920c47aa84bc",
   "metadata": {},
   "source": [
    "# Chargement des données et jointure de Csv\n",
    "\n",
    "Avant de commencer cette partie nous avons déjà réalisé une première lecture de nos données. Le but de notre projet est avant tout d'être capable de prédire l'écurie qui remporte la course. Pour cela comptons nous baser sur plusieurs variables, comme le palmarès du pilote, la position sur la course ou encore le circuit. Nos données sont séparées en plusieurs fichiers csv initialement au nombre de 14. Nous avons choisi de nous séparer de 3 de ces fichiers car nous les avons trouvé peu pertinents pour notre étude, à savoir :\n",
    "- seasons.csv : ne contient qu'une liste des années des saisons, celles-ci se trouvent également dans le fichier races.csv\n",
    "- sprint_results : les sprints sont une catégorie à part de la course, ces données n'ont donc aucune plus value pour notre étude\n",
    "- qualifying.csv : données redondantes car elles n'apportent rien de plus. Seule la position de départ serait pertinente mais elle est déjà fournie dans races.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77de83a9-9782-4e8a-a55d-8fcb22fbe7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier 'circuits.csv' chargé.\n",
      "Fichier 'constructor_results.csv' chargé.\n",
      "Fichier 'constructor_standings.csv' chargé.\n",
      "Fichier 'constructors.csv' chargé.\n",
      "Fichier 'driver_standings.csv' chargé.\n",
      "Fichier 'drivers.csv' chargé.\n",
      "Fichier 'lap_times.csv' chargé.\n",
      "Fichier 'pit_stops.csv' chargé.\n",
      "Fichier 'races.csv' chargé.\n",
      "Fichier 'results.csv' chargé.\n",
      "Fichier 'status.csv' chargé.\n",
      "\n",
      "--- Début de la fusion ---\n",
      "\n",
      " Fusion complétée avec succès\n",
      " Forme finale du dataset: (26499, 69)\n"
     ]
    }
   ],
   "source": [
    "dataframes = {}\n",
    "file_names = [\n",
    "    \"circuits.csv\", \"constructor_results.csv\", \"constructor_standings.csv\",\n",
    "    \"constructors.csv\", \"driver_standings.csv\", \"drivers.csv\",\n",
    "    \"lap_times.csv\", \"pit_stops.csv\", \"races.csv\", \"results.csv\", \"status.csv\"\n",
    "]\n",
    "na_val = '\\\\N'\n",
    "\n",
    "for f_name in file_names:\n",
    "    try:\n",
    "        key = f_name.split('.')[0]\n",
    "        dataframes[key] = pd.read_csv(f_name, na_values=[na_val])\n",
    "        print(f\"Fichier '{f_name}' chargé.\")\n",
    "    except FileNotFoundError:\n",
    "        # En cas de mauvaise écriture du csv ou non présence des fichiers dans le bon dossier\n",
    "        print(f\"ERREUR INATTENDUE : Fichier non trouvé : '{f_name}'\")\n",
    "        sys.exit()\n",
    "\n",
    "print(\"\\n--- Début de la fusion ---\")\n",
    "\n",
    "#Extraire les datasets\n",
    "results = dataframes.get('results')\n",
    "races = dataframes.get('races')\n",
    "circuits = dataframes.get('circuits')\n",
    "drivers = dataframes.get('drivers')\n",
    "constructors = dataframes.get('constructors')\n",
    "driver_standings = dataframes.get('driver_standings')\n",
    "constructor_standings = dataframes.get('constructor_standings')\n",
    "constructor_results = dataframes.get('constructor_results')\n",
    "status = dataframes.get('status')\n",
    "\n",
    "# Renommer les colonnes 'url' en conflit\n",
    "races = races.rename(columns={'url': 'race_url'})\n",
    "drivers = drivers.rename(columns={'url': 'driver_url'})\n",
    "constructors = constructors.rename(columns={'url': 'constructor_url'})\n",
    "circuits = circuits.rename(columns={'url': 'circuit_url'})\n",
    "\n",
    "# Fusion dans un ordre logique\n",
    "df_merged = (\n",
    "    results\n",
    "    .merge(races, on=\"raceId\", how=\"left\")\n",
    "    .merge(circuits, on=\"circuitId\", how=\"left\")\n",
    "    .merge(drivers, on=\"driverId\", how=\"left\")\n",
    "    .merge(constructors, on=\"constructorId\", how=\"left\")\n",
    "    .merge(status, on=\"statusId\", how=\"left\")\n",
    "    .merge(driver_standings, on=[\"raceId\", \"driverId\"], how=\"left\", suffixes=('_driver', '_driver_stand'))\n",
    "    .merge(constructor_standings, on=[\"raceId\", \"constructorId\"], how=\"left\", suffixes=('_constructor', '_constructor_stand'))\n",
    ")\n",
    "\n",
    "# Ajout de constructor_results\n",
    "if 'constructor_results' in dataframes:\n",
    "    cr = dataframes.get('constructor_results').copy()\n",
    "    join_keys = ['raceId', 'constructorId']\n",
    "    cols_to_prefix = [c for c in cr.columns if c not in join_keys]\n",
    "    cr = cr.rename(columns={c: f\"cr_{c}\" for c in cols_to_prefix})\n",
    "    df_merged = df_merged.merge(cr, on=join_keys, how='left')\n",
    "\n",
    "# Vérification du résultat\n",
    "print(\"\\n Fusion complétée avec succès\")\n",
    "print(f\" Forme finale du dataset: {df_merged.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcd4aa-fd39-41b3-b3b6-d144bf78212c",
   "metadata": {},
   "source": [
    "# Analyse Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc415fd-dd07-4fb6-ad4b-c46084462553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyse des Données Brutes (Colonnes Clés) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26499 entries, 0 to 26498\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   raceId         26499 non-null  int64\n",
      " 1   year           26499 non-null  int64\n",
      " 2   grid           26499 non-null  int64\n",
      " 3   positionOrder  26499 non-null  int64\n",
      " 4   circuitId      26499 non-null  int64\n",
      " 5   driverId       26499 non-null  int64\n",
      " 6   constructorId  26499 non-null  int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "\n",
      "Valeurs manquantes (avant pré-traitement) :\n",
      "raceId           0\n",
      "year             0\n",
      "grid             0\n",
      "positionOrder    0\n",
      "circuitId        0\n",
      "driverId         0\n",
      "constructorId    0\n",
      "dtype: int64\n",
      "NOTE : 'grid' a 0 NaNs (les '\\N' ont été lus comme 0 ou une autre valeur).\n",
      "      S'il y avait des NaNs (vrais zéros), ils seraient remplacés à l'Étape 2.\n",
      "\n",
      "Analyse des Features (X) - 'grid' (position de départ) :\n",
      "count    26499.000000\n",
      "mean        11.147062\n",
      "std          7.214294\n",
      "min          0.000000\n",
      "25%          5.000000\n",
      "50%         11.000000\n",
      "75%         17.000000\n",
      "max         34.000000\n",
      "Name: grid, dtype: float64\n",
      "Valeurs manquantes dans 'grid' : 0\n",
      "\n",
      "--- Analyse de la Cible (Y_winner) ---\n",
      "Distribution des Gagnants (1) vs Non-Gagnants (0) :\n",
      "positionOrder\n",
      "0    0.957923\n",
      "1    0.042077\n",
      "Name: proportion, dtype: float64\n",
      "NOTE : Seulement 4.21% des pilotes gagnent, le dataset est très déséquilibré.\n",
      "\n",
      "--- Relation: Position de Départ (grid) vs Taux de Victoire ---\n",
      "Taux de victoire en partant des stands (grid=0) : 0.00%\n",
      "\n",
      "Taux de victoire moyen pour le Top 10 sur la grille :\n",
      " grid  Y_winner\n",
      "    1  0.423865\n",
      "    2  0.237410\n",
      "    3  0.121755\n",
      "    4  0.058981\n",
      "    5  0.043789\n",
      "    6  0.035971\n",
      "    7  0.020499\n",
      "    8  0.015233\n",
      "    9  0.004468\n",
      "   10  0.010743\n",
      "\n",
      "NOTE : Partir de la pole (grid=1) donne 42.39% de chances de gagner.\n",
      "      Cette relation forte justifie l'utilisation de 'grid' comme feature principale.\n",
      "\n",
      "--- Relation: Circuit (circuitId) vs Nombre de Courses ---\n",
      "Top 15 des circuits par nombre de courses organisées (nb de pilotes) :\n",
      " circuitId  total_race_entries         name\n",
      "        14                1816       Toyota\n",
      "        14                1816     Red Bull\n",
      "        14                1816      Ferrari\n",
      "        14                1816      Renault\n",
      "        14                1816   BMW Sauber\n",
      "        14                1816      McLaren\n",
      "        14                1816   Toro Rosso\n",
      "        14                1816      Tyrrell\n",
      "        14                1816      Stewart\n",
      "        14                1816       Arrows\n",
      "        14                1816      Gordini\n",
      "        14                1816    Connaught\n",
      "        14                1816       Cooper\n",
      "        14                1816      Vanwall\n",
      "        14                1816 Aston Martin\n",
      "NOTE : L'analyse montre que les circuits n'ont pas tous le même nombre de données.\n"
     ]
    }
   ],
   "source": [
    "# Vérification des types et valeurs manquantes\n",
    "print(\"\\n--- Analyse des Données Brutes (Colonnes Clés) ---\")\n",
    "key_cols = ['raceId', 'year', 'grid', 'positionOrder', 'circuitId', 'driverId', 'constructorId']\n",
    "print(df_merged[key_cols].info())\n",
    "\n",
    "print(\"\\nValeurs manquantes (avant pré-traitement) :\")\n",
    "print(df_merged[key_cols].isna().sum())\n",
    "print(\"NOTE : 'grid' a 0 NaNs (les '\\\\N' ont été lus comme 0 ou une autre valeur).\")\n",
    "print(\"      S'il y avait des NaNs (vrais zéros), ils seraient remplacés à l'Étape 2.\")\n",
    "\n",
    "print(\"\\nAnalyse des Features (X) - 'grid' (position de départ) :\")\n",
    "print(df_merged['grid'].describe())\n",
    "print(f\"Valeurs manquantes dans 'grid' : {df_merged['grid'].isna().sum()}\")\n",
    "\n",
    "# Création et Analyse de la Cible (Y_winner)\n",
    "# Notre cible : 1 si le pilote a gagné (positionOrder == 1), 0 sinon.\n",
    "target = (df_merged['positionOrder'] == 1).astype(int)\n",
    "df_merged['Y_winner'] = target # Ajout temporaire pour l'analyse\n",
    "\n",
    "print(\"\\n--- Analyse de la Cible (Y_winner) ---\")\n",
    "print(\"Distribution des Gagnants (1) vs Non-Gagnants (0) :\")\n",
    "print(target.value_counts(normalize=True))\n",
    "print(f\"NOTE : Seulement {target.mean()*100:.2f}% des pilotes gagnent, le dataset est très déséquilibré.\")\n",
    "\n",
    "\n",
    "# Analyse Bivariée (Feature vs Cible)\n",
    "print(\"\\n--- Relation: Position de Départ (grid) vs Taux de Victoire ---\")\n",
    "# Calculer le taux de victoire moyen pour chaque position sur la grille\n",
    "# On ne regarde que le top 10 pour la lisibilité\n",
    "grid_win_rate = df_merged.groupby('grid')['Y_winner'].mean().reset_index()\n",
    "\n",
    "# Gérer le cas où grid=0 (pitlane) existe\n",
    "if 0 in grid_win_rate['grid'].values:\n",
    "    pitlane_win_rate = grid_win_rate[grid_win_rate['grid'] == 0]['Y_winner'].values[0]\n",
    "    print(f\"Taux de victoire en partant des stands (grid=0) : {pitlane_win_rate*100:.2f}%\")\n",
    "\n",
    "print(\"\\nTaux de victoire moyen pour le Top 10 sur la grille :\")\n",
    "# Affiche les positions 1 à 10 et leur taux de victoire\n",
    "print(grid_win_rate[(grid_win_rate['grid'] >= 1) & (grid_win_rate['grid'] <= 10)].sort_values('grid').to_string(index=False))\n",
    "\n",
    "pole_win_rate = grid_win_rate[grid_win_rate['grid'] == 1]['Y_winner'].values[0]\n",
    "print(f\"\\nNOTE : Partir de la pole (grid=1) donne {pole_win_rate*100:.2f}% de chances de gagner.\")\n",
    "print(\"      Cette relation forte justifie l'utilisation de 'grid' comme feature principale.\")\n",
    "\n",
    "print(\"\\n--- Relation: Circuit (circuitId) vs Nombre de Courses ---\")\n",
    "# Compter le nombre total de courses (lignes de résultat) par circuit\n",
    "# et fusionner avec le nom du circuit pour la lisibilité\n",
    "circuit_names = df_merged[['circuitId', 'name']].drop_duplicates()\n",
    "races_per_circuit = df_merged.groupby('circuitId').size().reset_index(name='total_race_entries')\n",
    "races_per_circuit = races_per_circuit.merge(circuit_names, on='circuitId', how='left')\n",
    "\n",
    "print(\"Top 15 des circuits par nombre de courses organisées (nb de pilotes) :\")\n",
    "print(races_per_circuit.sort_values('total_race_entries', ascending=False).head(15).to_string(index=False))\n",
    "print(\"NOTE : L'analyse montre que les circuits n'ont pas tous le même nombre de données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417c3d1-cdb4-4628-98c6-e1cb2032a9a3",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1565730a-6607-4700-927d-018ea0b7a67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sélectionnées : ['year', 'grid', 'circuitId']\n",
      "Valeurs 'grid' manquantes remplacées par 25.\n",
      "Données séparées en Train (avant 2020) et Test (2020+).\n",
      "Taille Entraînement : 24620 échantillons\n",
      "Taille Test : 1879 échantillons\n",
      "Feature 'grid' mise à l'échelle (StandardScaler).\n"
     ]
    }
   ],
   "source": [
    "# Création de la Cible (Y)\n",
    "Y = (df_merged['positionOrder'] == 1).astype(int)\n",
    "\n",
    "# Sélection des Features (X)\n",
    "features_df = df_merged[['year', 'grid', 'circuitId']].copy()\n",
    "print(f\"Features sélectionnées : {features_df.columns.to_list()}\")\n",
    "\n",
    "# Imputation (Nettoyage)\n",
    "grid_fill_value = 25\n",
    "features_df['grid'] = features_df['grid'].fillna(grid_fill_value)\n",
    "print(f\"Valeurs 'grid' manquantes remplacées par {grid_fill_value}.\")\n",
    "\n",
    "# Encodage Catégoriel\n",
    "features_df['circuitId'] = features_df['circuitId'].astype('category')\n",
    "X_processed = pd.get_dummies(features_df, columns=['circuitId'], drop_first=True, dtype=int)\n",
    "\n",
    "# Séparation Train/Test (Split Chronologique)\n",
    "cutoff_year = 2020\n",
    "train_indices = X_processed['year'] < cutoff_year\n",
    "test_indices = X_processed['year'] >= cutoff_year\n",
    "\n",
    "Y_train = Y[train_indices]\n",
    "Y_test = Y[test_indices]\n",
    "\n",
    "X_train_raw = X_processed[train_indices].drop('year', axis=1)\n",
    "X_test_raw = X_processed[test_indices].drop('year', axis=1)\n",
    "\n",
    "print(f\"Données séparées en Train (avant {cutoff_year}) et Test ({cutoff_year}+).\")\n",
    "print(f\"Taille Entraînement : {len(X_train_raw)} échantillons\")\n",
    "print(f\"Taille Test : {len(X_test_raw)} échantillons\")\n",
    "\n",
    "# Mise à l'échelle (Scaling)\n",
    "scaler = StandardScaler()\n",
    "grid_col = ['grid'] \n",
    "\n",
    "X_train = X_train_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "\n",
    "scaler.fit(X_train_raw[grid_col])\n",
    "X_train[grid_col] = scaler.transform(X_train_raw[grid_col])\n",
    "X_test[grid_col] = scaler.transform(X_test_raw[grid_col])\n",
    "print(\"Feature 'grid' mise à l'échelle (StandardScaler).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c5f66-0cfc-44f9-b408-f9f9c08f38aa",
   "metadata": {},
   "source": [
    "*Dans cette étape nous préparons les données pour le modèle. D'abord, nous créons notre variable cible binaire `Y` (1 pour une victoire, 0 sinon). Ensuite, pour notre baseline, nous sélectionnons un set minimal de features connues avant la course : `grid`, `circuitId`, et `year`, afin d'éviter toute fuite de données. Ensuite nous nettoyons nos données en nous assurant de remplacer les `grid` manquantes (départs des stands) par la valeur 25 (élevée car représente la pire position). La feature catégorielle `circuitId` est transformée en variables numériques.*\n",
    "\n",
    "*L'étape la plus importante est la séparation des données : nous effectuons un split chronologique pour simuler une prédiction réelle. L'année 2020 sert de point de césure : les 24 620 échantillons d'avant 2020 forment le set d'entraînement, et les 1 879 échantillons de 2020 et après forment le set de test. Enfin, la feature `grid` est mise à l'échelle (StandardScaler) en s'entraînant uniquement sur le set de training pour que le modèle de régression logistique puisse converger efficacement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f8132-4ef4-4eb2-aa60-a911f65107d2",
   "metadata": {},
   "source": [
    "# Formalisation du problème\n",
    "\n",
    "- Problème : Classification Binaire.\n",
    "- Objectif : Prédire si un pilote va gagner (1) ou non (0).\n",
    "- Modèle : Régression Logistique (Baseline).\n",
    "- Gestion Déséquilibre : Utilisation de 'class_weight='balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebc850-5336-443c-b644-9b7edaab41c7",
   "metadata": {},
   "source": [
    "# Modèle de Baseline (Régression Logistique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aba3cb0-e836-491b-8d72-8b1b2f996d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle...\n",
      "Entraînement terminé.\n",
      "\n",
      "--- RÉSULTATS DE L'ÉVALUATION (sur le Test Set) ---\n",
      "Accuracy (Précision globale) : 0.7504\n",
      "\n",
      "Matrice de Confusion :\n",
      " (Lignes = Réel, Colonnes = Prédiction)\n",
      "        Perdant (0) | Gagnant (1)\n",
      "Perdant (0) | 1325        | 460       \n",
      "Gagnant (1) | 9           | 85        \n",
      "\n",
      "TP (Gagnants bien prédits) : 85\n",
      "FN (Gagnants manqués) : 9\n",
      "FP (Faux positifs) : 460\n",
      "\n",
      "Rapport de Classification (Détail par classe) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Perdant (0)       0.99      0.74      0.85      1785\n",
      " Gagnant (1)       0.16      0.90      0.27        94\n",
      "\n",
      "    accuracy                           0.75      1879\n",
      "   macro avg       0.57      0.82      0.56      1879\n",
      "weighted avg       0.95      0.75      0.82      1879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "\n",
    "print(\"Entraînement du modèle...\")\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "# Prédiction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"\\n--- RÉSULTATS DE L'ÉVALUATION (sur le Test Set) ---\")\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "report = classification_report(Y_test, Y_pred, target_names=['Perdant (0)', 'Gagnant (1)'], zero_division=0)\n",
    "\n",
    "print(f\"Accuracy (Précision globale) : {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nMatrice de Confusion :\")\n",
    "print(\" (Lignes = Réel, Colonnes = Prédiction)\")\n",
    "print(f\"        Perdant (0) | Gagnant (1)\")\n",
    "print(f\"Perdant (0) | {cm[0][0]:<11} | {cm[0][1]:<10}\")\n",
    "print(f\"Gagnant (1) | {cm[1][0]:<11} | {cm[1][1]:<10}\")\n",
    "\n",
    "print(f\"\\nTP (Gagnants bien prédits) : {cm[1][1]}\")\n",
    "print(f\"FN (Gagnants manqués) : {cm[1][0]}\")\n",
    "print(f\"FP (Faux positifs) : {cm[0][1]}\")\n",
    "\n",
    "print(\"\\nRapport de Classification (Détail par classe) :\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d6f47-7858-4423-b899-edf0f45afe9d",
   "metadata": {},
   "source": [
    "Nous utilisons une Régression Logistique comme modèle de baseline. Le paramètre class_weight='balanced' est crucial pour forcer le modèle à gérer le fort déséquilibre des données (seulement 4.2% de gagnants). Le modèle est entraîné sur le set train (avant 2020) et évalué sur le set test (2020+). La précision globale (75%) est trompeuse.\n",
    "\n",
    "L'analyse du rapport de classification est plus parlante :\n",
    "\n",
    "    Recall (Rappel) : 0.90 - C'est un excellent résultat. Notre modèle a réussi à identifier 90% des vrais gagnants (85 sur 94) dans le set de test.\n",
    "\n",
    "    Precision : 0.16 - C'est la contrepartie. Pour trouver ces 85 gagnants, le modèle a également généré 460 \"faux positifs\".\n",
    "\n",
    "En conclusion, cette baseline est efficace pour trouver les vainqueurs, mais elle le fait au prix d'un grand nombre de fausses alertes.\n",
    "Il va donc nous falloir trouver une autre solution pour gérer ces 'imbalanced data' sans le faire au prix de notre précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a589a-af96-4e9c-85c6-558a3d6d33a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
